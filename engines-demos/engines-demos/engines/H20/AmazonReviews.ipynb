{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Predicting Good Amazon Reviews\n",
    "\n",
    "For this demo, we will be using the [Amazon Fine Food Reviews Data](https://www.kaggle.com/snap/amazon-fine-food-reviews).  The Amazon Fine Food Reviews dataset consists of 568,454 food reviews Amazon users left up to October 2012.\n",
    "\n",
    "This script is based off of the [Craigslist Word2Vec Demo](https://github.com/h2oai/h2o-3/blob/master/h2o-py/demos/word2vec_craigslistjobtitles.ipynb).\n",
    "\n",
    "## Import Data\n",
    "\n",
    "We will begin by importing our review data into our H2O cluster.  In this case, I will be starting up an H2O cluster on my local computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "ARTIFACTS_PATH = '../../artifacts/h2o/'\n",
    "os.makedirs(ARTIFACTS_PATH, exist_ok=True) # Create path if not exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import h2o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321 . connected.\n",
      "Warning: Your H2O cluster version is too old (3 months and 29 days)!Please download and install the latest version from http://h2o.ai/download/\n"
     ]
    },
    {
     "data": {
      "text/plain": "--------------------------  ----------------------------------------------------------------------------\nH2O_cluster_uptime:         1 hour 2 mins\nH2O_cluster_timezone:       Europe/Madrid\nH2O_data_parsing_timezone:  UTC\nH2O_cluster_version:        3.36.0.2\nH2O_cluster_version_age:    3 months and 29 days !!!\nH2O_cluster_name:           H2O_from_python_elizagonzalez_xeixu6\nH2O_cluster_total_nodes:    1\nH2O_cluster_free_memory:    1.568 Gb\nH2O_cluster_total_cores:    16\nH2O_cluster_allowed_cores:  16\nH2O_cluster_status:         locked, healthy\nH2O_connection_url:         http://localhost:54321\nH2O_connection_proxy:       {\"http\": null, \"https\": null}\nH2O_internal_security:      False\nH2O_API_Extensions:         Amazon S3, XGBoost, Algos, Infogram, AutoML, Core V3, TargetEncoder, Core V4\nPython_version:             3.8.10 final\n--------------------------  ----------------------------------------------------------------------------",
      "text/html": "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O_cluster_uptime:</td>\n<td>1 hour 2 mins</td></tr>\n<tr><td>H2O_cluster_timezone:</td>\n<td>Europe/Madrid</td></tr>\n<tr><td>H2O_data_parsing_timezone:</td>\n<td>UTC</td></tr>\n<tr><td>H2O_cluster_version:</td>\n<td>3.36.0.2</td></tr>\n<tr><td>H2O_cluster_version_age:</td>\n<td>3 months and 29 days !!!</td></tr>\n<tr><td>H2O_cluster_name:</td>\n<td>H2O_from_python_elizagonzalez_xeixu6</td></tr>\n<tr><td>H2O_cluster_total_nodes:</td>\n<td>1</td></tr>\n<tr><td>H2O_cluster_free_memory:</td>\n<td>1.568 Gb</td></tr>\n<tr><td>H2O_cluster_total_cores:</td>\n<td>16</td></tr>\n<tr><td>H2O_cluster_allowed_cores:</td>\n<td>16</td></tr>\n<tr><td>H2O_cluster_status:</td>\n<td>locked, healthy</td></tr>\n<tr><td>H2O_connection_url:</td>\n<td>http://localhost:54321</td></tr>\n<tr><td>H2O_connection_proxy:</td>\n<td>{\"http\": null, \"https\": null}</td></tr>\n<tr><td>H2O_internal_security:</td>\n<td>False</td></tr>\n<tr><td>H2O_API_Extensions:</td>\n<td>Amazon S3, XGBoost, Algos, Infogram, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n<tr><td>Python_version:</td>\n<td>3.8.10 final</td></tr></table></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "h2o.init(max_mem_size=\"4G\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Use local data file or download from GitHub\n",
    "import os\n",
    "docker_data_path = \"/home/h2o/data/nlp/AmazonReviews.csv\"\n",
    "if os.path.isfile(docker_data_path):\n",
    "  data_path = docker_data_path\n",
    "else:\n",
    "  data_path = \"https://s3.amazonaws.com/tomk/h2o-world/megan/AmazonReviews.csv\"\n",
    "\n",
    "\n",
    "# Load data into H2O\n",
    "reviews = h2o.import_file(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#' Add Target Column: \"PositiveReview\"\n",
    "reviews[\"PositiveReview\"] = (reviews[\"Score\"] >= 4).ifelse(\"1\", \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "<table>\n<thead>\n<tr><th>ProductId  </th><th>UserId        </th><th>Summary                               </th><th style=\"text-align: right;\">  Score</th><th style=\"text-align: right;\">  HelpfulnessDenominator</th><th style=\"text-align: right;\">    Id</th><th>ProfileName                                     </th><th style=\"text-align: right;\">  HelpfulnessNumerator</th><th style=\"text-align: right;\">       Time</th><th>Text                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        </th><th style=\"text-align: right;\">  PositiveReview</th></tr>\n</thead>\n<tbody>\n<tr><td>B00141QYSQ </td><td>A1YS02UZZGRDCT</td><td>Do Not Buy                            </td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">                       2</td><td style=\"text-align: right;\"> 41471</td><td>Evan Eberhardt                                  </td><td style=\"text-align: right;\">                     2</td><td style=\"text-align: right;\">1.34836e+09</td><td>These are made in China (do not buy ANY pet food from China).  Dogswell has been using propylene glycol to soften their treats (what are they thinkng?).  Do not purchase or support this company in any way until they clean up their act.  And for whatever reason Amazon doesn't allow returns of this item, so I had to toss mine out.  Bad business all around on this one.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            </td><td style=\"text-align: right;\">               0</td></tr>\n<tr><td>B0089SPEO2 </td><td>A3JOYNYL458QHP</td><td>Less lemon and less zing              </td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\"> 28582</td><td>coleridge                                       </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.32391e+09</td><td>Everything is ok, except it just isn't as good as it is in the bags.  Just considerably more bland -- less lemon and less zing.  Boring.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    </td><td style=\"text-align: right;\">               0</td></tr>\n<tr><td>B001PMCDK2 </td><td>A14TTMM0Z03Y2W</td><td>my cat goes crazy for these!          </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">389965</td><td>Lindsay S. Bradford                             </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.3106e+09 </td><td>Best cat treat ever. There isn't anything comparable to the love my cat has for these treats, he snubs away any other kind now.<br />I know he likes to manipulate me with his cattiness but these treats are my way of manipulating him to come sit on my lap and have some chill time. :)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 </td><td style=\"text-align: right;\">               1</td></tr>\n<tr><td>B002Q8JOSI </td><td>A17UQD2RSSQH5X</td><td>My dogs tell me these treats are YUMMY</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">212536</td><td>in the dark                                     </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.31613e+09</td><td>My two Corgis were thoroughly spoiled by my late husband (I spent a year and a half dieting them down a combined total of 25 pounds!)<br /><br />They are accustomed to the finest of fare, and they absolutely love the Wellness brand of treats.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          </td><td style=\"text-align: right;\">               1</td></tr>\n<tr><td>B00176G870 </td><td>A2F2MZW8EOGH5J</td><td>Yummy to the tummy                    </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">115971</td><td>daemoncycler \"When you arrive at a fork in th...</td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.33479e+09</td><td>We used to have drive down to the specialty pet food store for this product.  So glad we discovered Amazon.  As far as I can tell it is no more expensive & in some cases less - Prime membership is awesome.  Loving Pets treats are some of the best according to my dog.  They do not develop that nasty smell like some dog treats do.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  </td><td style=\"text-align: right;\">               1</td></tr>\n<tr><td>B001CHFUGY </td><td>A2M8VROSDPU4JT</td><td>Very good coffee                      </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">434484</td><td>Officefan \"Officefankt\"                         </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.27725e+09</td><td>I really liked this coffee, it was just as good as everyone claimed it was.  Strong, bold and flavorful!  I would recommend!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </td><td style=\"text-align: right;\">               1</td></tr>\n<tr><td>B0041CIR62 </td><td>A16I6WJUEBJ1C3</td><td>okay but not as healthy as it appears </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">138997</td><td>doctorsirena \"doctorsirena\"                     </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.34369e+09</td><td>I am always looking for healthier, whole grain versions of foods I enjoy.  Unfortunately, these Peacock brand noodles are yet another food masquerading as healthy.  The product title in big letters on the front says \"Brown Rice Vermicelli\", making the consumer think \"this is made with brown rice, so it should be a healthy choice\".  But the first indication that it is not is when looking at the fiber content on the nutrition facts - only 0.6g per 2oz serving.  Then onto the ingredients list to see why so low... contains brown rice, sago starch and water.  The sago starch comes from palms and must not have much (if any) fiber.<br /><br />The Annie Chun's Maifun Brown Rice Noodles (sold on Amazon and in my local healthy grocer) has become one of my staples and is my frame of reference when comparing to the Peacock brand.  The Annie Chun's product is made with 100% whole grain, with ingredients brown rice flour and water.  Per 2oz serving, it has 4g fiber and pretty much the same calories and other nutrients as the Peacock brand.<br /><br />If you do try this Peacock brand noodles and have not used rice noodles before, you will need to seek guidance elsewhere on preparation.  As others have pointed out, the Peacock package gives almost no directions on how to prepare the product, aside from a brief mention in the recipes (in the header text it does say that they are \"easy-to-cook\" but does not say how).  It also contains a very strange recipe for rice noodles: Aglio Olio style - this is an Italian recipe for noodles with olive oil/garlic/sprinkled with grated cheese that I think would not be very tasty.  The second recipe appears to be for a soup with veggie strips.  Neither recipe gives amounts or much direction.  In comparison, the Annie Chun's package gives clear, specific directions on rice noodle preparation and two recipes.<br /><br />I use rice noodles = maifun = rice sticks = sometimes called vermicelli for making the Vietnamese salad \"bun tofu\", to serve with stir-fried veggies or in lettuce rolls.  They can also be used in spring rolls/egg rolls.  When cooking with thin rice noodles, be careful not to oversoak/overcook/overmix or they tend to disintegrate.  Asian rice noodle vermicelli (maifun) are not the same as Italian vermicelli and are not readily interchangeable.  If making an Italian recipe, the best results would be expected from Italian pasta and not maifun.<br /><br />A few final notes...  Both Peacock and Annie Chun's brown rice noodles are gluten free.  The Peacock is made in Singapore and the Annie Chun's in Thailand.  The Peacock noodles do taste fine (kind of bland), but so do the Annie Chun's.  At this time, they are both approximately the same price.  Peacock come in an plastic bag with some noodle crushage upon shipping; Annie Chun's are perfect upon removal from their cellophane bag in a box.  Overall, I highly recommend the Annie Chun's Maifun as a healthier option over the Peacock brand.  On a related note, the Annie Chun's soba and brown rice pad thai noodles are also excellent.<br /><br />Rating for this product: 2.5 stars rounded down to 2 stars.</td><td style=\"text-align: right;\">               0</td></tr>\n<tr><td>B001R3BQFW </td><td>AM50E42AFUVNL </td><td>Taste great.                          </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">126555</td><td>T. Higley \"Tina\"                                </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.32356e+09</td><td>I have tried many different drink mix, this is the best tasting by far. It does not have the after taste of the sweetener and I really like it, it is pretty strong, so I use a big water bottle (20 oz) for one tube, it still a little stronger than I like, but it is just my taste.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </td><td style=\"text-align: right;\">               1</td></tr>\n<tr><td>B005HGAV8I </td><td>A2I5KDNOESGJ1H</td><td>variety galore                        </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       1</td><td style=\"text-align: right;\">438837</td><td>TJ                                              </td><td style=\"text-align: right;\">                     1</td><td style=\"text-align: right;\">1.33402e+09</td><td>This is my favorite item to order for my Keurig. There are so many flavors, my finicky palate never gets bored!  The only downside is there are probably 5-6 decaf varieties.  I don't drink decaf (I REQUIRE copious amounts of caffeine), so they sit on the shelf...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     </td><td style=\"text-align: right;\">               1</td></tr>\n<tr><td>B000GFYRHQ </td><td>A3A7YUR6FS6ZCI</td><td>Bigelow Earl Grey Green Tea           </td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">                       0</td><td style=\"text-align: right;\">245379</td><td>Tea Lover                                       </td><td style=\"text-align: right;\">                     0</td><td style=\"text-align: right;\">1.17841e+09</td><td>Tastes like Earl Grey, but it's green tea so it's healthier.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </td><td style=\"text-align: right;\">               1</td></tr>\n</tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">  PositiveReview</th><th style=\"text-align: right;\">  Count</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">               0</td><td style=\"text-align: right;\">  21791</td></tr>\n<tr><td style=\"text-align: right;\">               1</td><td style=\"text-align: right;\">  78209</td></tr>\n</tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[\"PositiveReview\"].table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train Baseline Model\n",
    "\n",
    "We will start by training a baseline model that does not use the review and instead uses other attributes in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Find the 80th quantile of time in the dataset\n",
    "time_split = reviews[\"Time\"].quantile(prob = [0.8])[1]\n",
    "reviews[\"Train\"] = (reviews[\"Time\"] < time_split).ifelse(\"Yes\", \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = reviews[reviews[\"Train\"] == \"Yes\"]\n",
    "test = reviews[reviews[\"Train\"] == \"No\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm Model Build progress: |██████████████████████████████████████████████████████| (done) 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OGradientBoostingEstimator :  Gradient Boosting Machine\n",
      "Model Key:  gbm_baseline.hex\n",
      "\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/plain": "     number_of_trees  number_of_internal_trees  model_size_in_bytes  \\\n0               50.0                      50.0              26565.0   \n\n   min_depth  max_depth  mean_depth  min_leaves  max_leaves  mean_leaves  \n0        5.0        5.0         5.0        20.0        32.0        30.68  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>number_of_trees</th>\n      <th>number_of_internal_trees</th>\n      <th>model_size_in_bytes</th>\n      <th>min_depth</th>\n      <th>max_depth</th>\n      <th>mean_depth</th>\n      <th>min_leaves</th>\n      <th>max_leaves</th>\n      <th>mean_leaves</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>50.0</td>\n      <td>50.0</td>\n      <td>26565.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>20.0</td>\n      <td>32.0</td>\n      <td>30.68</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.13095677774210135\n",
      "RMSE: 0.3618795072149034\n",
      "LogLoss: 0.4225308080796732\n",
      "Mean Per-Class Error: 0.3664365877144608\n",
      "AUC: 0.7734025089714696\n",
      "AUCPR: 0.9108873370521795\n",
      "Gini: 0.5468050179429391\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.527033748723949: \n"
     ]
    },
    {
     "data": {
      "text/plain": "               0        1   Error                Rate\n0      0  5016.0  12115.0  0.7072   (12115.0/17131.0)\n1      1  1614.0  61247.0  0.0257    (1614.0/62861.0)\n2  Total  6630.0  73362.0  0.1716   (13729.0/79992.0)",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>5016.0</td>\n      <td>12115.0</td>\n      <td>0.7072</td>\n      <td>(12115.0/17131.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1614.0</td>\n      <td>61247.0</td>\n      <td>0.0257</td>\n      <td>(1614.0/62861.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>6630.0</td>\n      <td>73362.0</td>\n      <td>0.1716</td>\n      <td>(13729.0/79992.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/plain": "                         metric  threshold         value    idx\n0                        max f1   0.527034      0.899217  256.0\n1                        max f2   0.268467      0.951053  341.0\n2                  max f0point5   0.736557      0.873269  167.0\n3                  max accuracy   0.587735      0.829508  233.0\n4                 max precision   0.952026      1.000000    0.0\n5                    max recall   0.065807      1.000000  397.0\n6               max specificity   0.952026      1.000000    0.0\n7              max absolute_mcc   0.644497      0.418259  207.0\n8    max min_per_class_accuracy   0.824435      0.697730  107.0\n9   max mean_per_class_accuracy   0.800090      0.708199  128.0\n10                      max tns   0.952026  17131.000000    0.0\n11                      max fns   0.952026  62839.000000    0.0\n12                      max fps   0.049679  17131.000000  399.0\n13                      max tps   0.065807  62861.000000  397.0\n14                      max tnr   0.952026      1.000000    0.0\n15                      max fnr   0.952026      0.999650    0.0\n16                      max fpr   0.049679      1.000000  399.0\n17                      max tpr   0.065807      1.000000  397.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.527034</td>\n      <td>0.899217</td>\n      <td>256.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.268467</td>\n      <td>0.951053</td>\n      <td>341.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.736557</td>\n      <td>0.873269</td>\n      <td>167.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.587735</td>\n      <td>0.829508</td>\n      <td>233.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.952026</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.065807</td>\n      <td>1.000000</td>\n      <td>397.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.952026</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.644497</td>\n      <td>0.418259</td>\n      <td>207.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.824435</td>\n      <td>0.697730</td>\n      <td>107.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.800090</td>\n      <td>0.708199</td>\n      <td>128.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.952026</td>\n      <td>17131.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.952026</td>\n      <td>62839.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.049679</td>\n      <td>17131.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.065807</td>\n      <td>62861.000000</td>\n      <td>397.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.952026</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.952026</td>\n      <td>0.999650</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.049679</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.065807</td>\n      <td>1.000000</td>\n      <td>397.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 78.58 %, avg score: 78.57 %\n"
     ]
    },
    {
     "data": {
      "text/plain": "    group  cumulative_data_fraction  lower_threshold      lift  \\\n0       1                  0.010014         0.925071  1.255047   \n1       2                  0.020015         0.918354  1.239118   \n2       3                  0.030041         0.914395  1.236028   \n3       4                  0.040017         0.911995  1.200763   \n4       5                  0.050018         0.910264  1.210486   \n5       6                  0.100135         0.903173  1.192850   \n6       7                  0.150015         0.897408  1.168551   \n7       8                  0.200008         0.889871  1.168467   \n8       9                  0.300055         0.874648  1.154381   \n9      10                  0.400003         0.857089  1.123703   \n10     11                  0.500025         0.844739  1.104888   \n11     12                  0.600085         0.826558  1.075062   \n12     13                  0.700083         0.805284  1.050280   \n13     14                  0.799992         0.750291  0.969518   \n14     15                  0.900040         0.568869  0.780877   \n15     16                  1.000000         0.048232  0.361895   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.255047       0.986267  0.933300                  0.986267   \n1          1.247087       0.973750  0.921189                  0.980012   \n2          1.243396       0.971322  0.916349                  0.977112   \n3          1.232768       0.943609  0.913211                  0.968760   \n4          1.228313       0.951250  0.911105                  0.965259   \n5          1.210564       0.937391  0.906373                  0.951311   \n6          1.196595       0.918296  0.900175                  0.940333   \n7          1.189564       0.918230  0.894409                  0.934808   \n8          1.177833       0.907160  0.880898                  0.925590   \n9          1.164308       0.883052  0.867407                  0.914961   \n10         1.152422       0.868266  0.851127                  0.905620   \n11         1.139522       0.844828  0.835435                  0.895484   \n12         1.126775       0.825353  0.816459                  0.885466   \n13         1.107136       0.761887  0.784899                  0.870033   \n14         1.070869       0.613645  0.654201                  0.841533   \n15         1.000000       0.284392  0.356784                  0.785841   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           0.933300      0.012567                 0.012567  25.504658   \n1           0.927248      0.012392                 0.024960  23.911821   \n2           0.923611      0.012392                 0.037352  23.602814   \n3           0.921018      0.011979                 0.049331  20.076316   \n4           0.919036      0.012106                 0.061437  21.048647   \n5           0.912698      0.059783                 0.121220  19.285042   \n6           0.908534      0.058287                 0.179507  16.855145   \n7           0.905004      0.058415                 0.237922  16.846723   \n8           0.896966      0.115493                 0.353415  15.438074   \n9           0.889580      0.112311                 0.465726  12.370290   \n10          0.881888      0.110514                 0.576240  10.488811   \n11          0.874142      0.107571                 0.683810   7.506162   \n12          0.865903      0.105025                 0.788836   5.027999   \n13          0.855786      0.096865                 0.885700  -3.048224   \n14          0.833378      0.078125                 0.963825 -21.912344   \n15          0.785738      0.036175                 1.000000 -63.810470   \n\n    cumulative_gain  kolmogorov_smirnov  \n0         25.504658            0.011925  \n1         24.708737            0.023092  \n2         24.339636            0.034142  \n3         23.276803            0.043494  \n4         22.831283            0.053323  \n5         21.056392            0.098454  \n6         19.659477            0.137712  \n7         18.956421            0.177038  \n8         17.783297            0.249159  \n9         16.430764            0.306891  \n10        15.242165            0.355879  \n11        13.952240            0.390949  \n12        12.677531            0.414427  \n13        10.713563            0.400206  \n14         7.086901            0.297839  \n15         0.000000            0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n      <th>kolmogorov_smirnov</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.010014</td>\n      <td>0.925071</td>\n      <td>1.255047</td>\n      <td>1.255047</td>\n      <td>0.986267</td>\n      <td>0.933300</td>\n      <td>0.986267</td>\n      <td>0.933300</td>\n      <td>0.012567</td>\n      <td>0.012567</td>\n      <td>25.504658</td>\n      <td>25.504658</td>\n      <td>0.011925</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.020015</td>\n      <td>0.918354</td>\n      <td>1.239118</td>\n      <td>1.247087</td>\n      <td>0.973750</td>\n      <td>0.921189</td>\n      <td>0.980012</td>\n      <td>0.927248</td>\n      <td>0.012392</td>\n      <td>0.024960</td>\n      <td>23.911821</td>\n      <td>24.708737</td>\n      <td>0.023092</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.030041</td>\n      <td>0.914395</td>\n      <td>1.236028</td>\n      <td>1.243396</td>\n      <td>0.971322</td>\n      <td>0.916349</td>\n      <td>0.977112</td>\n      <td>0.923611</td>\n      <td>0.012392</td>\n      <td>0.037352</td>\n      <td>23.602814</td>\n      <td>24.339636</td>\n      <td>0.034142</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.040017</td>\n      <td>0.911995</td>\n      <td>1.200763</td>\n      <td>1.232768</td>\n      <td>0.943609</td>\n      <td>0.913211</td>\n      <td>0.968760</td>\n      <td>0.921018</td>\n      <td>0.011979</td>\n      <td>0.049331</td>\n      <td>20.076316</td>\n      <td>23.276803</td>\n      <td>0.043494</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.050018</td>\n      <td>0.910264</td>\n      <td>1.210486</td>\n      <td>1.228313</td>\n      <td>0.951250</td>\n      <td>0.911105</td>\n      <td>0.965259</td>\n      <td>0.919036</td>\n      <td>0.012106</td>\n      <td>0.061437</td>\n      <td>21.048647</td>\n      <td>22.831283</td>\n      <td>0.053323</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0.100135</td>\n      <td>0.903173</td>\n      <td>1.192850</td>\n      <td>1.210564</td>\n      <td>0.937391</td>\n      <td>0.906373</td>\n      <td>0.951311</td>\n      <td>0.912698</td>\n      <td>0.059783</td>\n      <td>0.121220</td>\n      <td>19.285042</td>\n      <td>21.056392</td>\n      <td>0.098454</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0.150015</td>\n      <td>0.897408</td>\n      <td>1.168551</td>\n      <td>1.196595</td>\n      <td>0.918296</td>\n      <td>0.900175</td>\n      <td>0.940333</td>\n      <td>0.908534</td>\n      <td>0.058287</td>\n      <td>0.179507</td>\n      <td>16.855145</td>\n      <td>19.659477</td>\n      <td>0.137712</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0.200008</td>\n      <td>0.889871</td>\n      <td>1.168467</td>\n      <td>1.189564</td>\n      <td>0.918230</td>\n      <td>0.894409</td>\n      <td>0.934808</td>\n      <td>0.905004</td>\n      <td>0.058415</td>\n      <td>0.237922</td>\n      <td>16.846723</td>\n      <td>18.956421</td>\n      <td>0.177038</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0.300055</td>\n      <td>0.874648</td>\n      <td>1.154381</td>\n      <td>1.177833</td>\n      <td>0.907160</td>\n      <td>0.880898</td>\n      <td>0.925590</td>\n      <td>0.896966</td>\n      <td>0.115493</td>\n      <td>0.353415</td>\n      <td>15.438074</td>\n      <td>17.783297</td>\n      <td>0.249159</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>0.400003</td>\n      <td>0.857089</td>\n      <td>1.123703</td>\n      <td>1.164308</td>\n      <td>0.883052</td>\n      <td>0.867407</td>\n      <td>0.914961</td>\n      <td>0.889580</td>\n      <td>0.112311</td>\n      <td>0.465726</td>\n      <td>12.370290</td>\n      <td>16.430764</td>\n      <td>0.306891</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>0.500025</td>\n      <td>0.844739</td>\n      <td>1.104888</td>\n      <td>1.152422</td>\n      <td>0.868266</td>\n      <td>0.851127</td>\n      <td>0.905620</td>\n      <td>0.881888</td>\n      <td>0.110514</td>\n      <td>0.576240</td>\n      <td>10.488811</td>\n      <td>15.242165</td>\n      <td>0.355879</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>0.600085</td>\n      <td>0.826558</td>\n      <td>1.075062</td>\n      <td>1.139522</td>\n      <td>0.844828</td>\n      <td>0.835435</td>\n      <td>0.895484</td>\n      <td>0.874142</td>\n      <td>0.107571</td>\n      <td>0.683810</td>\n      <td>7.506162</td>\n      <td>13.952240</td>\n      <td>0.390949</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>0.700083</td>\n      <td>0.805284</td>\n      <td>1.050280</td>\n      <td>1.126775</td>\n      <td>0.825353</td>\n      <td>0.816459</td>\n      <td>0.885466</td>\n      <td>0.865903</td>\n      <td>0.105025</td>\n      <td>0.788836</td>\n      <td>5.027999</td>\n      <td>12.677531</td>\n      <td>0.414427</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>0.799992</td>\n      <td>0.750291</td>\n      <td>0.969518</td>\n      <td>1.107136</td>\n      <td>0.761887</td>\n      <td>0.784899</td>\n      <td>0.870033</td>\n      <td>0.855786</td>\n      <td>0.096865</td>\n      <td>0.885700</td>\n      <td>-3.048224</td>\n      <td>10.713563</td>\n      <td>0.400206</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>0.900040</td>\n      <td>0.568869</td>\n      <td>0.780877</td>\n      <td>1.070869</td>\n      <td>0.613645</td>\n      <td>0.654201</td>\n      <td>0.841533</td>\n      <td>0.833378</td>\n      <td>0.078125</td>\n      <td>0.963825</td>\n      <td>-21.912344</td>\n      <td>7.086901</td>\n      <td>0.297839</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>1.000000</td>\n      <td>0.048232</td>\n      <td>0.361895</td>\n      <td>1.000000</td>\n      <td>0.284392</td>\n      <td>0.356784</td>\n      <td>0.785841</td>\n      <td>0.785738</td>\n      <td>0.036175</td>\n      <td>1.000000</td>\n      <td>-63.810470</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: gbm\n",
      "** Reported on validation data. **\n",
      "\n",
      "MSE: 0.16702675167057898\n",
      "RMSE: 0.4086890647797895\n",
      "LogLoss: 0.5166125543011013\n",
      "Mean Per-Class Error: 0.46296820768192243\n",
      "AUC: 0.6161364288422755\n",
      "AUCPR: 0.8139424591501248\n",
      "Gini: 0.23227285768455097\n",
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.45931625811239496: \n"
     ]
    },
    {
     "data": {
      "text/plain": "              0        1   Error               Rate\n0      0  384.0   4276.0  0.9176    (4276.0/4660.0)\n1      1  128.0  15220.0  0.0083    (128.0/15348.0)\n2  Total  512.0  19496.0  0.2201   (4404.0/20008.0)",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>384.0</td>\n      <td>4276.0</td>\n      <td>0.9176</td>\n      <td>(4276.0/4660.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>128.0</td>\n      <td>15220.0</td>\n      <td>0.0083</td>\n      <td>(128.0/15348.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>512.0</td>\n      <td>19496.0</td>\n      <td>0.2201</td>\n      <td>(4404.0/20008.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Maximum Metrics: Maximum metrics at their respective thresholds\n"
     ]
    },
    {
     "data": {
      "text/plain": "                         metric  threshold         value    idx\n0                        max f1   0.459316      0.873608  292.0\n1                        max f2   0.268408      0.942886  347.0\n2                  max f0point5   0.765918      0.830179  163.0\n3                  max accuracy   0.632496      0.784036  221.0\n4                 max precision   0.902818      1.000000    0.0\n5                    max recall   0.059845      1.000000  399.0\n6               max specificity   0.902818      1.000000    0.0\n7              max absolute_mcc   0.750033      0.270509  172.0\n8    max min_per_class_accuracy   0.834895      0.569313   83.0\n9   max mean_per_class_accuracy   0.790481      0.602411  145.0\n10                      max tns   0.902818   4660.000000    0.0\n11                      max fns   0.902818  15347.000000    0.0\n12                      max fps   0.059845   4660.000000  399.0\n13                      max tps   0.059845  15348.000000  399.0\n14                      max tnr   0.902818      1.000000    0.0\n15                      max fnr   0.902818      0.999935    0.0\n16                      max fpr   0.059845      1.000000  399.0\n17                      max tpr   0.059845      1.000000  399.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>metric</th>\n      <th>threshold</th>\n      <th>value</th>\n      <th>idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>max f1</td>\n      <td>0.459316</td>\n      <td>0.873608</td>\n      <td>292.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>max f2</td>\n      <td>0.268408</td>\n      <td>0.942886</td>\n      <td>347.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>max f0point5</td>\n      <td>0.765918</td>\n      <td>0.830179</td>\n      <td>163.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>max accuracy</td>\n      <td>0.632496</td>\n      <td>0.784036</td>\n      <td>221.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>max precision</td>\n      <td>0.902818</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>max recall</td>\n      <td>0.059845</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>max specificity</td>\n      <td>0.902818</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>max absolute_mcc</td>\n      <td>0.750033</td>\n      <td>0.270509</td>\n      <td>172.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>max min_per_class_accuracy</td>\n      <td>0.834895</td>\n      <td>0.569313</td>\n      <td>83.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>max mean_per_class_accuracy</td>\n      <td>0.790481</td>\n      <td>0.602411</td>\n      <td>145.0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>max tns</td>\n      <td>0.902818</td>\n      <td>4660.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>max fns</td>\n      <td>0.902818</td>\n      <td>15347.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>max fps</td>\n      <td>0.059845</td>\n      <td>4660.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>max tps</td>\n      <td>0.059845</td>\n      <td>15348.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>max tnr</td>\n      <td>0.902818</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>max fnr</td>\n      <td>0.902818</td>\n      <td>0.999935</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>max fpr</td>\n      <td>0.059845</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>max tpr</td>\n      <td>0.059845</td>\n      <td>1.000000</td>\n      <td>399.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gains/Lift Table: Avg response rate: 76.71 %, avg score: 80.92 %\n"
     ]
    },
    {
     "data": {
      "text/plain": "    group  cumulative_data_fraction  lower_threshold      lift  \\\n0       1                  0.010046         0.882908  1.134995   \n1       2                  0.020092         0.875996  1.024738   \n2       3                  0.044582         0.873617  1.048219   \n3       4                  0.053079         0.871717  0.981551   \n4       5                  0.110056         0.867069  1.058907   \n5       6                  0.154338         0.863193  1.077034   \n6       7                  0.206767         0.858838  1.065019   \n7       8                  0.300130         0.855122  1.074721   \n8       9                  0.405338         0.849397  1.060238   \n9      10                  0.500000         0.837672  1.057215   \n10     11                  0.600310         0.829650  1.062644   \n11     12                  0.700920         0.821287  1.046525   \n12     13                  0.802429         0.809798  1.036608   \n13     14                  0.900040         0.734965  0.976549   \n14     15                  1.000000         0.059346  0.560558   \n\n    cumulative_lift  response_rate     score  cumulative_response_rate  \\\n0          1.134995       0.870647  0.889106                  0.870647   \n1          1.079867       0.786070  0.878952                  0.828358   \n2          1.062482       0.804082  0.873984                  0.815022   \n3          1.049527       0.752941  0.872084                  0.805085   \n4          1.054383       0.812281  0.869057                  0.808810   \n5          1.060882       0.826185  0.864890                  0.813795   \n6          1.061931       0.816969  0.861009                  0.814600   \n7          1.065910       0.824411  0.856942                  0.817652   \n8          1.064438       0.813302  0.851804                  0.816523   \n9          1.063070       0.810982  0.844024                  0.815474   \n10         1.062999       0.815147  0.833868                  0.815419   \n11         1.060634       0.802782  0.824466                  0.813605   \n12         1.057595       0.795175  0.815447                  0.811274   \n13         1.048805       0.749104  0.793567                  0.804531   \n14         1.000000       0.430000  0.532962                  0.767093   \n\n    cumulative_score  capture_rate  cumulative_capture_rate       gain  \\\n0           0.889106      0.011402                 0.011402  13.499482   \n1           0.884029      0.010295                 0.021697   2.473818   \n2           0.878511      0.025671                 0.047368   4.821901   \n3           0.877482      0.008340                 0.055708  -1.844885   \n4           0.873120      0.060334                 0.116041   5.890750   \n5           0.870759      0.047694                 0.163735   7.703359   \n6           0.868287      0.055838                 0.219573   6.501867   \n7           0.864758      0.100339                 0.319911   7.472101   \n8           0.861395      0.111545                 0.431457   6.023845   \n9           0.858107      0.100078                 0.531535   5.721454   \n10          0.854056      0.106594                 0.638129   6.264405   \n11          0.849809      0.105291                 0.743419   4.652467   \n12          0.845462      0.105225                 0.848645   3.660785   \n13          0.839834      0.095322                 0.943967  -2.345115   \n14          0.809159      0.056033                 1.000000 -43.944227   \n\n    cumulative_gain  kolmogorov_smirnov  \n0         13.499482            0.005823  \n1          7.986650            0.006890  \n2          6.248167            0.011960  \n3          4.952669            0.011287  \n4          5.438324            0.025698  \n5          6.088201            0.040344  \n6          6.193092            0.054980  \n7          6.590959            0.084933  \n8          6.443761            0.112144  \n9          6.307011            0.135398  \n10         6.299891            0.162378  \n11         6.063421            0.182475  \n12         5.759481            0.198430  \n13         4.880523            0.188602  \n14         0.000000            0.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>group</th>\n      <th>cumulative_data_fraction</th>\n      <th>lower_threshold</th>\n      <th>lift</th>\n      <th>cumulative_lift</th>\n      <th>response_rate</th>\n      <th>score</th>\n      <th>cumulative_response_rate</th>\n      <th>cumulative_score</th>\n      <th>capture_rate</th>\n      <th>cumulative_capture_rate</th>\n      <th>gain</th>\n      <th>cumulative_gain</th>\n      <th>kolmogorov_smirnov</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.010046</td>\n      <td>0.882908</td>\n      <td>1.134995</td>\n      <td>1.134995</td>\n      <td>0.870647</td>\n      <td>0.889106</td>\n      <td>0.870647</td>\n      <td>0.889106</td>\n      <td>0.011402</td>\n      <td>0.011402</td>\n      <td>13.499482</td>\n      <td>13.499482</td>\n      <td>0.005823</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.020092</td>\n      <td>0.875996</td>\n      <td>1.024738</td>\n      <td>1.079867</td>\n      <td>0.786070</td>\n      <td>0.878952</td>\n      <td>0.828358</td>\n      <td>0.884029</td>\n      <td>0.010295</td>\n      <td>0.021697</td>\n      <td>2.473818</td>\n      <td>7.986650</td>\n      <td>0.006890</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.044582</td>\n      <td>0.873617</td>\n      <td>1.048219</td>\n      <td>1.062482</td>\n      <td>0.804082</td>\n      <td>0.873984</td>\n      <td>0.815022</td>\n      <td>0.878511</td>\n      <td>0.025671</td>\n      <td>0.047368</td>\n      <td>4.821901</td>\n      <td>6.248167</td>\n      <td>0.011960</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.053079</td>\n      <td>0.871717</td>\n      <td>0.981551</td>\n      <td>1.049527</td>\n      <td>0.752941</td>\n      <td>0.872084</td>\n      <td>0.805085</td>\n      <td>0.877482</td>\n      <td>0.008340</td>\n      <td>0.055708</td>\n      <td>-1.844885</td>\n      <td>4.952669</td>\n      <td>0.011287</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.110056</td>\n      <td>0.867069</td>\n      <td>1.058907</td>\n      <td>1.054383</td>\n      <td>0.812281</td>\n      <td>0.869057</td>\n      <td>0.808810</td>\n      <td>0.873120</td>\n      <td>0.060334</td>\n      <td>0.116041</td>\n      <td>5.890750</td>\n      <td>5.438324</td>\n      <td>0.025698</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>0.154338</td>\n      <td>0.863193</td>\n      <td>1.077034</td>\n      <td>1.060882</td>\n      <td>0.826185</td>\n      <td>0.864890</td>\n      <td>0.813795</td>\n      <td>0.870759</td>\n      <td>0.047694</td>\n      <td>0.163735</td>\n      <td>7.703359</td>\n      <td>6.088201</td>\n      <td>0.040344</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>0.206767</td>\n      <td>0.858838</td>\n      <td>1.065019</td>\n      <td>1.061931</td>\n      <td>0.816969</td>\n      <td>0.861009</td>\n      <td>0.814600</td>\n      <td>0.868287</td>\n      <td>0.055838</td>\n      <td>0.219573</td>\n      <td>6.501867</td>\n      <td>6.193092</td>\n      <td>0.054980</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>0.300130</td>\n      <td>0.855122</td>\n      <td>1.074721</td>\n      <td>1.065910</td>\n      <td>0.824411</td>\n      <td>0.856942</td>\n      <td>0.817652</td>\n      <td>0.864758</td>\n      <td>0.100339</td>\n      <td>0.319911</td>\n      <td>7.472101</td>\n      <td>6.590959</td>\n      <td>0.084933</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0.405338</td>\n      <td>0.849397</td>\n      <td>1.060238</td>\n      <td>1.064438</td>\n      <td>0.813302</td>\n      <td>0.851804</td>\n      <td>0.816523</td>\n      <td>0.861395</td>\n      <td>0.111545</td>\n      <td>0.431457</td>\n      <td>6.023845</td>\n      <td>6.443761</td>\n      <td>0.112144</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>0.500000</td>\n      <td>0.837672</td>\n      <td>1.057215</td>\n      <td>1.063070</td>\n      <td>0.810982</td>\n      <td>0.844024</td>\n      <td>0.815474</td>\n      <td>0.858107</td>\n      <td>0.100078</td>\n      <td>0.531535</td>\n      <td>5.721454</td>\n      <td>6.307011</td>\n      <td>0.135398</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>0.600310</td>\n      <td>0.829650</td>\n      <td>1.062644</td>\n      <td>1.062999</td>\n      <td>0.815147</td>\n      <td>0.833868</td>\n      <td>0.815419</td>\n      <td>0.854056</td>\n      <td>0.106594</td>\n      <td>0.638129</td>\n      <td>6.264405</td>\n      <td>6.299891</td>\n      <td>0.162378</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>0.700920</td>\n      <td>0.821287</td>\n      <td>1.046525</td>\n      <td>1.060634</td>\n      <td>0.802782</td>\n      <td>0.824466</td>\n      <td>0.813605</td>\n      <td>0.849809</td>\n      <td>0.105291</td>\n      <td>0.743419</td>\n      <td>4.652467</td>\n      <td>6.063421</td>\n      <td>0.182475</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>0.802429</td>\n      <td>0.809798</td>\n      <td>1.036608</td>\n      <td>1.057595</td>\n      <td>0.795175</td>\n      <td>0.815447</td>\n      <td>0.811274</td>\n      <td>0.845462</td>\n      <td>0.105225</td>\n      <td>0.848645</td>\n      <td>3.660785</td>\n      <td>5.759481</td>\n      <td>0.198430</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>0.900040</td>\n      <td>0.734965</td>\n      <td>0.976549</td>\n      <td>1.048805</td>\n      <td>0.749104</td>\n      <td>0.793567</td>\n      <td>0.804531</td>\n      <td>0.839834</td>\n      <td>0.095322</td>\n      <td>0.943967</td>\n      <td>-2.345115</td>\n      <td>4.880523</td>\n      <td>0.188602</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>1.000000</td>\n      <td>0.059346</td>\n      <td>0.560558</td>\n      <td>1.000000</td>\n      <td>0.430000</td>\n      <td>0.532962</td>\n      <td>0.767093</td>\n      <td>0.809159</td>\n      <td>0.056033</td>\n      <td>1.000000</td>\n      <td>-43.944227</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/plain": "               timestamp    duration  number_of_trees  training_rmse  \\\n0    2022-05-25 16:11:44   0.003 sec              0.0       0.410238   \n1    2022-05-25 16:11:44   0.096 sec             10.0       0.378922   \n2    2022-05-25 16:11:44   0.188 sec             20.0       0.370371   \n3    2022-05-25 16:11:45   0.323 sec             30.0       0.366882   \n4    2022-05-25 16:11:45   0.457 sec             40.0       0.364583   \n5    2022-05-25 16:11:45   0.553 sec             50.0       0.361880   \n\n   training_logloss  training_auc  training_pr_auc  training_lift  \\\n0          0.519415      0.500000         0.785841       1.000000   \n1          0.456027      0.738113         0.892783       1.229748   \n2          0.439853      0.747508         0.897608       1.229859   \n3          0.433010      0.754446         0.901176       1.239733   \n4          0.428173      0.762348         0.905554       1.250308   \n5          0.422531      0.773403         0.910887       1.255047   \n\n   training_classification_error  validation_rmse  validation_logloss  \\\n0                       0.214159         0.423099            0.543788   \n1                       0.182081         0.411394            0.519999   \n2                       0.176818         0.409348            0.517033   \n3                       0.175893         0.408871            0.516586   \n4                       0.174117         0.408982            0.517169   \n5                       0.171630         0.408689            0.516613   \n\n   validation_auc  validation_pr_auc  validation_lift  \\\n0        0.500000           0.767093         1.000000   \n1        0.602428           0.806377         1.050615   \n2        0.610503           0.809318         1.038944   \n3        0.611240           0.812058         1.142902   \n4        0.613924           0.812089         1.070138   \n5        0.616136           0.813942         1.134995   \n\n   validation_classification_error  \n0                         0.232907  \n1                         0.222111  \n2                         0.220662  \n3                         0.220412  \n4                         0.220312  \n5                         0.220112  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>timestamp</th>\n      <th>duration</th>\n      <th>number_of_trees</th>\n      <th>training_rmse</th>\n      <th>training_logloss</th>\n      <th>training_auc</th>\n      <th>training_pr_auc</th>\n      <th>training_lift</th>\n      <th>training_classification_error</th>\n      <th>validation_rmse</th>\n      <th>validation_logloss</th>\n      <th>validation_auc</th>\n      <th>validation_pr_auc</th>\n      <th>validation_lift</th>\n      <th>validation_classification_error</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td></td>\n      <td>2022-05-25 16:11:44</td>\n      <td>0.003 sec</td>\n      <td>0.0</td>\n      <td>0.410238</td>\n      <td>0.519415</td>\n      <td>0.500000</td>\n      <td>0.785841</td>\n      <td>1.000000</td>\n      <td>0.214159</td>\n      <td>0.423099</td>\n      <td>0.543788</td>\n      <td>0.500000</td>\n      <td>0.767093</td>\n      <td>1.000000</td>\n      <td>0.232907</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>2022-05-25 16:11:44</td>\n      <td>0.096 sec</td>\n      <td>10.0</td>\n      <td>0.378922</td>\n      <td>0.456027</td>\n      <td>0.738113</td>\n      <td>0.892783</td>\n      <td>1.229748</td>\n      <td>0.182081</td>\n      <td>0.411394</td>\n      <td>0.519999</td>\n      <td>0.602428</td>\n      <td>0.806377</td>\n      <td>1.050615</td>\n      <td>0.222111</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td></td>\n      <td>2022-05-25 16:11:44</td>\n      <td>0.188 sec</td>\n      <td>20.0</td>\n      <td>0.370371</td>\n      <td>0.439853</td>\n      <td>0.747508</td>\n      <td>0.897608</td>\n      <td>1.229859</td>\n      <td>0.176818</td>\n      <td>0.409348</td>\n      <td>0.517033</td>\n      <td>0.610503</td>\n      <td>0.809318</td>\n      <td>1.038944</td>\n      <td>0.220662</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td></td>\n      <td>2022-05-25 16:11:45</td>\n      <td>0.323 sec</td>\n      <td>30.0</td>\n      <td>0.366882</td>\n      <td>0.433010</td>\n      <td>0.754446</td>\n      <td>0.901176</td>\n      <td>1.239733</td>\n      <td>0.175893</td>\n      <td>0.408871</td>\n      <td>0.516586</td>\n      <td>0.611240</td>\n      <td>0.812058</td>\n      <td>1.142902</td>\n      <td>0.220412</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>2022-05-25 16:11:45</td>\n      <td>0.457 sec</td>\n      <td>40.0</td>\n      <td>0.364583</td>\n      <td>0.428173</td>\n      <td>0.762348</td>\n      <td>0.905554</td>\n      <td>1.250308</td>\n      <td>0.174117</td>\n      <td>0.408982</td>\n      <td>0.517169</td>\n      <td>0.613924</td>\n      <td>0.812089</td>\n      <td>1.070138</td>\n      <td>0.220312</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>2022-05-25 16:11:45</td>\n      <td>0.553 sec</td>\n      <td>50.0</td>\n      <td>0.361880</td>\n      <td>0.422531</td>\n      <td>0.773403</td>\n      <td>0.910887</td>\n      <td>1.255047</td>\n      <td>0.171630</td>\n      <td>0.408689</td>\n      <td>0.516613</td>\n      <td>0.616136</td>\n      <td>0.813942</td>\n      <td>1.134995</td>\n      <td>0.220112</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/plain": "                 variable  relative_importance  scaled_importance  percentage\n0    HelpfulnessNumerator          6629.697754           1.000000    0.430967\n1  HelpfulnessDenominator          5733.745117           0.864858    0.372725\n2                    Time          1460.428345           0.220286    0.094936\n3               ProductId          1310.930908           0.197736    0.085218\n4                  UserId           248.504898           0.037484    0.016154",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>variable</th>\n      <th>relative_importance</th>\n      <th>scaled_importance</th>\n      <th>percentage</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>HelpfulnessNumerator</td>\n      <td>6629.697754</td>\n      <td>1.000000</td>\n      <td>0.430967</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>HelpfulnessDenominator</td>\n      <td>5733.745117</td>\n      <td>0.864858</td>\n      <td>0.372725</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Time</td>\n      <td>1460.428345</td>\n      <td>0.220286</td>\n      <td>0.094936</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ProductId</td>\n      <td>1310.930908</td>\n      <td>0.197736</td>\n      <td>0.085218</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>UserId</td>\n      <td>248.504898</td>\n      <td>0.037484</td>\n      <td>0.016154</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from h2o.estimators import H2OGradientBoostingEstimator\n",
    "\n",
    "predictors = ['ProductId', 'UserId', 'HelpfulnessNumerator', 'HelpfulnessDenominator', 'Time']\n",
    "response = 'PositiveReview'\n",
    "\n",
    "gbm_baseline = H2OGradientBoostingEstimator(stopping_metric = \"AUC\", stopping_tolerance = 0.001,\n",
    "                                            stopping_rounds = 5, score_tree_interval = 10,\n",
    "                                            model_id = \"gbm_baseline.hex\"\n",
    "                                           )\n",
    "gbm_baseline.train(x = predictors, y = response, \n",
    "                   training_frame = train, validation_frame = test\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on Validation Data: 0.616\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC on Validation Data: \" + str(round(gbm_baseline.auc(valid = True), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see that there is a big room for improvement.  Our error is 22%.  To improve our model, we will train word embeddings for the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.45931625811239496: \n"
     ]
    },
    {
     "data": {
      "text/plain": "              0        1   Error               Rate\n0      0  384.0   4276.0  0.9176    (4276.0/4660.0)\n1      1  128.0  15220.0  0.0083    (128.0/15348.0)\n2  Total  512.0  19496.0  0.2201   (4404.0/20008.0)",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>Error</th>\n      <th>Rate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>384.0</td>\n      <td>4276.0</td>\n      <td>0.9176</td>\n      <td>(4276.0/4660.0)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>128.0</td>\n      <td>15220.0</td>\n      <td>0.0083</td>\n      <td>(128.0/15348.0)</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Total</td>\n      <td>512.0</td>\n      <td>19496.0</td>\n      <td>0.2201</td>\n      <td>(4404.0/20008.0)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm_baseline.confusion_matrix(valid = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The variable importance plot below shows us that the most important variable is `HelpfulnessNumerator`.  Looking at the partial dependency plot for that variable, we see that the more people who find the review helpful, the more likely it is a good review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1008x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<h2o.plot._plot_result._MObject at 0x7f6418146220>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm_baseline.varimp_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PartialDependencePlot progress: |████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 504x720 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline  \n",
    "pdp_helpfulness = gbm_baseline.partial_plot(train, cols = [\"HelpfulnessNumerator\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tokenize Words in Review\n",
    "\n",
    "Our first step will be to tokenize the words in the review column. We will do this by creating a function called `tokenize`.  This will split the reviews into words and remove any stop words, small words, or words with numbers in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set Stop Words\n",
    "# The STOP WORDS we are importing are from the nltk package\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Use local data file or download from GitHub\n",
    "docker_data_path = \"/home/h2o/data/nlp/stopwords.csv\"\n",
    "if os.path.isfile(docker_data_path):\n",
    "  data_path = docker_data_path\n",
    "else:\n",
    "  data_path = \"https://raw.githubusercontent.com/h2oai/h2o-tutorials/master/h2o-world-2017/nlp/stopwords.csv\"\n",
    "\n",
    "STOP_WORDS = pd.read_csv(data_path, header=0)\n",
    "STOP_WORDS = list(STOP_WORDS['STOP_WORD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def tokenize(sentences, stop_word = STOP_WORDS):\n",
    "    tokenized = sentences.tokenize(\"\\\\W+\")\n",
    "    tokenized_lower = tokenized.tolower()\n",
    "    tokenized_filtered = tokenized_lower[(tokenized_lower.nchar() >= 2) | (tokenized_lower.isna()),:]\n",
    "    tokenized_words = tokenized_filtered[tokenized_filtered.grep(\"[0-9]\",invert=True,output_logical=True),:]\n",
    "    tokenized_words = tokenized_words[(tokenized_words.isna()) | (~ tokenized_words.isin(STOP_WORDS)),:]\n",
    "    return tokenized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Break reviews into sequence of words\n",
    "words = tokenize(reviews[\"Text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(4154796, 1)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train Word2Vec Model\n",
    "\n",
    "Now that we've tokenized our words, we can train a word2vec model.  We can use the `find_synonms` function to sanity check our word2vec model after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"w2v_h2o\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec Model Build progress: |█████████████████████████████████████████████████| (done) 100%\n",
      "Model Details\n",
      "=============\n",
      "H2OWord2vecEstimator :  Word2Vec\n",
      "Model Key:  w2v_h2o\n",
      "\n",
      "No model summary for this model\n"
     ]
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Word2Vec Model\n",
    "from h2o.estimators.word2vec import H2OWord2vecEstimator\n",
    "\n",
    "# This takes time to run - left commented out\n",
    "w2v_model = H2OWord2vecEstimator(vec_size = 100, model_id = model_name)\n",
    "w2v_model.train(training_frame=words)\n",
    "\n",
    "# Pre-trained model available on s3: https://s3.amazonaws.com/tomk/h2o-world/megan/w2v.hex\n",
    "#w2v_model = h2o.load_model(\"/home/h2o/data/megan/w2v.hex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "model_file = w2v_model.download_mojo(path = ARTIFACTS_PATH + \"/\", get_genmodel_jar = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('coffe', 0.8110815286636353),\n             ('espresso', 0.7782745957374573),\n             ('coffees', 0.7435689568519592),\n             ('expresso', 0.7354498505592346),\n             ('folgers', 0.7242841720581055)])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check - find synonyms for the word 'coffee'\n",
    "w2v_model.find_synonyms(\"coffee\", count = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "OrderedDict([('moldy', 0.7223275899887085),\n             ('rancid', 0.7063090801239014),\n             ('inedible', 0.6635894775390625),\n             ('unedible', 0.6437413692474365),\n             ('expired', 0.6282831430435181)])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check - find synonyms for the word 'stale'\n",
    "w2v_model.find_synonyms(\"stale\", count = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now that we have a word embedding for each word in our vocabulary, we will aggregate the words for each review using the `transform` function.  This will give us one aggregated word embedding for each review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "data": {
      "text/html": "<table>\n<thead>\n<tr><th>C1       </th></tr>\n</thead>\n<tbody>\n<tr><td>china    </td></tr>\n<tr><td>made     </td></tr>\n<tr><td>         </td></tr>\n<tr><td>customize</td></tr>\n<tr><td>products </td></tr>\n<tr><td>         </td></tr>\n</tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from random import random\n",
    "\n",
    "# Calculate a vector for each review\n",
    "sstr = [\"china made\", \"customize products\"]\n",
    "h2oframe = h2o.H2OFrame(python_obj=sstr)\n",
    "\n",
    "worddd = tokenize(h2oframe)\n",
    "print(worddd)\n",
    "\n",
    "\n",
    "\n",
    "review_vecs = w2v_model.transform(worddd, aggregate_method = \"AVERAGE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">        C1</th><th style=\"text-align: right;\">       C2</th><th style=\"text-align: right;\">        C3</th><th style=\"text-align: right;\">      C4</th><th style=\"text-align: right;\">         C5</th><th style=\"text-align: right;\">        C6</th><th style=\"text-align: right;\">        C7</th><th style=\"text-align: right;\">       C8</th><th style=\"text-align: right;\">        C9</th><th style=\"text-align: right;\">       C10</th><th style=\"text-align: right;\">      C11</th><th style=\"text-align: right;\">       C12</th><th style=\"text-align: right;\">       C13</th><th style=\"text-align: right;\">      C14</th><th style=\"text-align: right;\">        C15</th><th style=\"text-align: right;\">      C16</th><th style=\"text-align: right;\">      C17</th><th style=\"text-align: right;\">       C18</th><th style=\"text-align: right;\">      C19</th><th style=\"text-align: right;\">       C20</th><th style=\"text-align: right;\">      C21</th><th style=\"text-align: right;\">       C22</th><th style=\"text-align: right;\">      C23</th><th style=\"text-align: right;\">       C24</th><th style=\"text-align: right;\">      C25</th><th style=\"text-align: right;\">       C26</th><th style=\"text-align: right;\">       C27</th><th style=\"text-align: right;\">       C28</th><th style=\"text-align: right;\">      C29</th><th style=\"text-align: right;\">     C30</th><th style=\"text-align: right;\">      C31</th><th style=\"text-align: right;\">       C32</th><th style=\"text-align: right;\">       C33</th><th style=\"text-align: right;\">     C34</th><th style=\"text-align: right;\">        C35</th><th style=\"text-align: right;\">       C36</th><th style=\"text-align: right;\">     C37</th><th style=\"text-align: right;\">       C38</th><th style=\"text-align: right;\">       C39</th><th style=\"text-align: right;\">       C40</th><th style=\"text-align: right;\">     C41</th><th style=\"text-align: right;\">       C42</th><th style=\"text-align: right;\">       C43</th><th style=\"text-align: right;\">     C44</th><th style=\"text-align: right;\">      C45</th><th style=\"text-align: right;\">     C46</th><th style=\"text-align: right;\">       C47</th><th style=\"text-align: right;\">      C48</th><th style=\"text-align: right;\">        C49</th><th style=\"text-align: right;\">       C50</th><th style=\"text-align: right;\">       C51</th><th style=\"text-align: right;\">      C52</th><th style=\"text-align: right;\">      C53</th><th style=\"text-align: right;\">      C54</th><th style=\"text-align: right;\">     C55</th><th style=\"text-align: right;\">      C56</th><th style=\"text-align: right;\">      C57</th><th style=\"text-align: right;\">       C58</th><th style=\"text-align: right;\">       C59</th><th style=\"text-align: right;\">      C60</th><th style=\"text-align: right;\">      C61</th><th style=\"text-align: right;\">       C62</th><th style=\"text-align: right;\">      C63</th><th style=\"text-align: right;\">       C64</th><th style=\"text-align: right;\">       C65</th><th style=\"text-align: right;\">       C66</th><th style=\"text-align: right;\">      C67</th><th style=\"text-align: right;\">        C68</th><th style=\"text-align: right;\">       C69</th><th style=\"text-align: right;\">      C70</th><th style=\"text-align: right;\">      C71</th><th style=\"text-align: right;\">       C72</th><th style=\"text-align: right;\">      C73</th><th style=\"text-align: right;\">       C74</th><th style=\"text-align: right;\">     C75</th><th style=\"text-align: right;\">        C76</th><th style=\"text-align: right;\">      C77</th><th style=\"text-align: right;\">      C78</th><th style=\"text-align: right;\">      C79</th><th style=\"text-align: right;\">      C80</th><th style=\"text-align: right;\">       C81</th><th style=\"text-align: right;\">      C82</th><th style=\"text-align: right;\">     C83</th><th style=\"text-align: right;\">      C84</th><th style=\"text-align: right;\">       C85</th><th style=\"text-align: right;\">      C86</th><th style=\"text-align: right;\">        C87</th><th style=\"text-align: right;\">       C88</th><th style=\"text-align: right;\">       C89</th><th style=\"text-align: right;\">       C90</th><th style=\"text-align: right;\">       C91</th><th style=\"text-align: right;\">      C92</th><th style=\"text-align: right;\">      C93</th><th style=\"text-align: right;\">      C94</th><th style=\"text-align: right;\">       C95</th><th style=\"text-align: right;\">     C96</th><th style=\"text-align: right;\">       C97</th><th style=\"text-align: right;\">      C98</th><th style=\"text-align: right;\">     C99</th><th style=\"text-align: right;\">      C100</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">-0.0816077</td><td style=\"text-align: right;\">0.214889 </td><td style=\"text-align: right;\">-0.307657 </td><td style=\"text-align: right;\">0.113978</td><td style=\"text-align: right;\"> 0.00027057</td><td style=\"text-align: right;\"> 0.138412 </td><td style=\"text-align: right;\">0.00691679</td><td style=\"text-align: right;\">0.36561  </td><td style=\"text-align: right;\"> 0.278528 </td><td style=\"text-align: right;\">-0.0540835</td><td style=\"text-align: right;\"> 0.153812</td><td style=\"text-align: right;\">-0.0860648</td><td style=\"text-align: right;\"> 0.0203943</td><td style=\"text-align: right;\">-0.322637</td><td style=\"text-align: right;\">-0.00573067</td><td style=\"text-align: right;\">0.230636 </td><td style=\"text-align: right;\">-0.103212</td><td style=\"text-align: right;\"> 0.213941 </td><td style=\"text-align: right;\">-0.16556 </td><td style=\"text-align: right;\"> 0.139192 </td><td style=\"text-align: right;\">0.0693622</td><td style=\"text-align: right;\"> 0.250769 </td><td style=\"text-align: right;\"> 0.272027</td><td style=\"text-align: right;\">-0.08715  </td><td style=\"text-align: right;\">-0.10553 </td><td style=\"text-align: right;\">-0.297414 </td><td style=\"text-align: right;\"> 0.0546593</td><td style=\"text-align: right;\">-0.0949512</td><td style=\"text-align: right;\">0.116673 </td><td style=\"text-align: right;\">0.189249</td><td style=\"text-align: right;\">0.110142 </td><td style=\"text-align: right;\">-0.308488 </td><td style=\"text-align: right;\"> 0.105003 </td><td style=\"text-align: right;\">0.10036 </td><td style=\"text-align: right;\">-0.00881984</td><td style=\"text-align: right;\">-0.282222 </td><td style=\"text-align: right;\">0.17145 </td><td style=\"text-align: right;\"> 0.115448 </td><td style=\"text-align: right;\">-0.0996504</td><td style=\"text-align: right;\"> 0.0997609</td><td style=\"text-align: right;\">0.483123</td><td style=\"text-align: right;\">-0.194344 </td><td style=\"text-align: right;\"> 0.0474723</td><td style=\"text-align: right;\">0.273722</td><td style=\"text-align: right;\">0.371998 </td><td style=\"text-align: right;\">0.524123</td><td style=\"text-align: right;\">-0.0320062</td><td style=\"text-align: right;\">0.307905 </td><td style=\"text-align: right;\">-0.130628  </td><td style=\"text-align: right;\">-0.0106966</td><td style=\"text-align: right;\">0.00992888</td><td style=\"text-align: right;\">0.198041 </td><td style=\"text-align: right;\">0.191829 </td><td style=\"text-align: right;\">-0.213074</td><td style=\"text-align: right;\">0.171478</td><td style=\"text-align: right;\">0.0338113</td><td style=\"text-align: right;\">-0.456074</td><td style=\"text-align: right;\"> 0.0580885</td><td style=\"text-align: right;\">-0.216214 </td><td style=\"text-align: right;\">-0.352708</td><td style=\"text-align: right;\">-0.194515</td><td style=\"text-align: right;\">-0.203572 </td><td style=\"text-align: right;\">0.231888 </td><td style=\"text-align: right;\"> 0.0527101</td><td style=\"text-align: right;\">-0.28966  </td><td style=\"text-align: right;\"> 0.0649091</td><td style=\"text-align: right;\">-0.1052  </td><td style=\"text-align: right;\"> 0.00142777</td><td style=\"text-align: right;\">-0.0299432</td><td style=\"text-align: right;\">0.0786715</td><td style=\"text-align: right;\">-0.123208</td><td style=\"text-align: right;\">-0.150016 </td><td style=\"text-align: right;\">-0.281049</td><td style=\"text-align: right;\">-0.0702727</td><td style=\"text-align: right;\">0.293717</td><td style=\"text-align: right;\">-0.100326  </td><td style=\"text-align: right;\">0.113266 </td><td style=\"text-align: right;\">0.105386 </td><td style=\"text-align: right;\">0.0229311</td><td style=\"text-align: right;\">-0.377291</td><td style=\"text-align: right;\">-0.159523 </td><td style=\"text-align: right;\">0.262679 </td><td style=\"text-align: right;\">0.307532</td><td style=\"text-align: right;\"> 0.183813</td><td style=\"text-align: right;\"> 0.092173 </td><td style=\"text-align: right;\">-0.32188 </td><td style=\"text-align: right;\">-0.00128596</td><td style=\"text-align: right;\">-0.217639 </td><td style=\"text-align: right;\">-0.450734 </td><td style=\"text-align: right;\">-0.0783577</td><td style=\"text-align: right;\">-0.0639362</td><td style=\"text-align: right;\"> 0.221463</td><td style=\"text-align: right;\">0.22869  </td><td style=\"text-align: right;\">-0.251199</td><td style=\"text-align: right;\">-0.18105  </td><td style=\"text-align: right;\">0.117042</td><td style=\"text-align: right;\"> 0.39287  </td><td style=\"text-align: right;\">0.0719734</td><td style=\"text-align: right;\">0.101399</td><td style=\"text-align: right;\">0.0811238 </td></tr>\n<tr><td style=\"text-align: right;\">-0.542093 </td><td style=\"text-align: right;\">0.0287305</td><td style=\"text-align: right;\">-0.0715067</td><td style=\"text-align: right;\">0.130877</td><td style=\"text-align: right;\">-0.0786903 </td><td style=\"text-align: right;\">-0.0800896</td><td style=\"text-align: right;\">0.213474  </td><td style=\"text-align: right;\">0.0526528</td><td style=\"text-align: right;\">-0.0768262</td><td style=\"text-align: right;\"> 0.302959 </td><td style=\"text-align: right;\">-0.143485</td><td style=\"text-align: right;\"> 0.0433302</td><td style=\"text-align: right;\">-0.0244515</td><td style=\"text-align: right;\">-0.250103</td><td style=\"text-align: right;\">-0.00719982</td><td style=\"text-align: right;\">0.0839543</td><td style=\"text-align: right;\">-0.171316</td><td style=\"text-align: right;\">-0.0265685</td><td style=\"text-align: right;\">-0.039793</td><td style=\"text-align: right;\">-0.0999562</td><td style=\"text-align: right;\">0.077055 </td><td style=\"text-align: right;\">-0.0680511</td><td style=\"text-align: right;\">-0.115671</td><td style=\"text-align: right;\"> 0.0482465</td><td style=\"text-align: right;\"> 0.077714</td><td style=\"text-align: right;\">-0.0572347</td><td style=\"text-align: right;\">-0.15163  </td><td style=\"text-align: right;\">-0.0305565</td><td style=\"text-align: right;\">0.0127482</td><td style=\"text-align: right;\">0.109133</td><td style=\"text-align: right;\">0.0636291</td><td style=\"text-align: right;\"> 0.0251258</td><td style=\"text-align: right;\">-0.0646952</td><td style=\"text-align: right;\">0.371928</td><td style=\"text-align: right;\">-0.0642786 </td><td style=\"text-align: right;\">-0.0932554</td><td style=\"text-align: right;\">0.117289</td><td style=\"text-align: right;\">-0.0942678</td><td style=\"text-align: right;\"> 0.0760709</td><td style=\"text-align: right;\">-0.0941605</td><td style=\"text-align: right;\">0.173358</td><td style=\"text-align: right;\">-0.0810103</td><td style=\"text-align: right;\">-0.0202513</td><td style=\"text-align: right;\">0.049358</td><td style=\"text-align: right;\">0.0596398</td><td style=\"text-align: right;\">0.178157</td><td style=\"text-align: right;\">-0.0469513</td><td style=\"text-align: right;\">0.0447995</td><td style=\"text-align: right;\">-0.00165783</td><td style=\"text-align: right;\"> 0.150459 </td><td style=\"text-align: right;\">0.207618  </td><td style=\"text-align: right;\">0.0366321</td><td style=\"text-align: right;\">0.0203057</td><td style=\"text-align: right;\">-0.255318</td><td style=\"text-align: right;\">0.149172</td><td style=\"text-align: right;\">0.300996 </td><td style=\"text-align: right;\">-0.137496</td><td style=\"text-align: right;\">-0.119603 </td><td style=\"text-align: right;\">-0.0431783</td><td style=\"text-align: right;\"> 0.013205</td><td style=\"text-align: right;\">-0.117686</td><td style=\"text-align: right;\">-0.0827614</td><td style=\"text-align: right;\">0.0827395</td><td style=\"text-align: right;\">-0.0815991</td><td style=\"text-align: right;\">-0.0129945</td><td style=\"text-align: right;\">-0.0371696</td><td style=\"text-align: right;\">-0.190237</td><td style=\"text-align: right;\">-0.173469  </td><td style=\"text-align: right;\">-0.106007 </td><td style=\"text-align: right;\">0.105588 </td><td style=\"text-align: right;\"> 0.103356</td><td style=\"text-align: right;\">-0.0749166</td><td style=\"text-align: right;\"> 0.171426</td><td style=\"text-align: right;\">-0.0778559</td><td style=\"text-align: right;\">0.228072</td><td style=\"text-align: right;\"> 0.00200307</td><td style=\"text-align: right;\">0.0646572</td><td style=\"text-align: right;\">0.0496543</td><td style=\"text-align: right;\">0.0624498</td><td style=\"text-align: right;\">-0.260267</td><td style=\"text-align: right;\">-0.0167242</td><td style=\"text-align: right;\">0.0974978</td><td style=\"text-align: right;\">0.165607</td><td style=\"text-align: right;\">-0.100675</td><td style=\"text-align: right;\">-0.0053649</td><td style=\"text-align: right;\">-0.133288</td><td style=\"text-align: right;\"> 0.0513312 </td><td style=\"text-align: right;\"> 0.0345764</td><td style=\"text-align: right;\">-0.0731594</td><td style=\"text-align: right;\">-0.0258986</td><td style=\"text-align: right;\"> 0.133958 </td><td style=\"text-align: right;\">-0.104151</td><td style=\"text-align: right;\">0.0740616</td><td style=\"text-align: right;\">-0.120769</td><td style=\"text-align: right;\">-0.0825723</td><td style=\"text-align: right;\">0.159589</td><td style=\"text-align: right;\">-0.0856584</td><td style=\"text-align: right;\">0.0190439</td><td style=\"text-align: right;\">0.113556</td><td style=\"text-align: right;\">0.00573282</td></tr>\n</tbody>\n</table>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": ""
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Add aggregated word embeddings \n",
    "ext_reviews = reviews.cbind(review_vecs)\n",
    "ext_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train GBM Model to Predict Good Review\n",
    "\n",
    "We will train a GBM model with the same parameters as our baseline gbm.  This time, however, we will add the aggregated word embeddings as predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ext_train = ext_reviews[ext_reviews[\"Train\"] == \"Yes\"]\n",
    "ext_test = ext_reviews[ext_reviews[\"Train\"] == \"No\"]\n",
    "\n",
    "ext_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictors = predictors + review_vecs.names\n",
    "response = 'PositiveReview'\n",
    "\n",
    "gbm_embeddings = H2OGradientBoostingEstimator(stopping_metric = \"AUC\", stopping_tolerance = 0.001,\n",
    "                                              stopping_rounds = 5, score_tree_interval = 10,\n",
    "                                              model_id = \"gbm_embeddings.hex\"\n",
    "                                             )\n",
    "gbm_embeddings.train(x = predictors, y = response, \n",
    "                   training_frame = ext_train, validation_frame = ext_test\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Baseline AUC: \" + str(round(gbm_baseline.auc(valid = True), 3)))\n",
    "print(\"With Embeddings AUC: \" + str(round(gbm_embeddings.auc(valid = True), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gbm_embeddings.confusion_matrix(valid = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Adding Summary\n",
    "\n",
    "We saw that the review column is not the only column with text.  We also have a column called `Summary` which summarizes the review.  We will add the word embeddings of the summary to see if this improves our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Break summaries into sequence of words\n",
    "summary_words = tokenize(reviews[\"Summary\"].ascharacter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Add aggregated summary word embeddings\n",
    "summary_vecs = w2v_model.transform(summary_words, aggregate_method = \"AVERAGE\")\n",
    "summary_vecs.names = [\"summary_\" + s for s in summary_vecs.names]\n",
    "\n",
    "ext_reviews = ext_reviews.cbind(summary_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ext_train = ext_reviews[ext_reviews[\"Train\"] == \"Yes\"]\n",
    "ext_test = ext_reviews[ext_reviews[\"Train\"] == \"No\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "predictors = predictors + summary_vecs.names\n",
    "response = 'PositiveReview'\n",
    "\n",
    "gbm_plus_summary = H2OGradientBoostingEstimator(stopping_metric = \"AUC\", stopping_tolerance = 0.001,\n",
    "                                              stopping_rounds = 5, score_tree_interval = 10,\n",
    "                                              model_id = \"gbm_plus_summary.hex\"\n",
    "                                             )\n",
    "gbm_plus_summary.train(x = predictors, y = response, \n",
    "                       training_frame = ext_train, validation_frame = ext_test\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Baseline AUC: \" + str(round(gbm_baseline.auc(valid = True), 3)))\n",
    "print(\"With Embeddings AUC: \" + str(round(gbm_embeddings.auc(valid = True), 3)))\n",
    "print(\"With Summary and Review Embeddings AUC: \" + str(round(gbm_plus_summary.auc(valid = True), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gbm_plus_summary.varimp_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pdp_word_vecs = gbm_plus_summary.partial_plot(data = ext_train, cols = [\"C43\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can see that a low `C43` is associated with a smaller probability of positive review.  Let's see what words have a low `C43` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get Word Embeddings per Word\n",
    "unique_words = words.asfactor().unique().ascharacter()\n",
    "unique_words.col_names = [\"Word\"]\n",
    "word_embeddings = w2v_model.transform(unique_words, aggregate_method=\"None\")\n",
    "word_embeddings = unique_words.cbind(word_embeddings)\n",
    "word_embeddings = word_embeddings[~(word_embeddings[\"C1\"].isna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "word_embeddings[\"C43\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "low_c43_words = word_embeddings[word_embeddings[\"C43\"] < -1.1]\n",
    "low_c43_words[[\"Word\", \"C43\"]].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The words with low `C43` like `contacted`, `answered`, `emails`, `phone` and `refund` all seem to be related to contacting for a refund.  Words like: `salmonella` are obviously an indicator of a negative review for a food product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Predict on New Reviews\n",
    "\n",
    "Now that we've built a model we are satisifed with, we will see how the model performs on new reviews.\n",
    "\n",
    "* *\"The taste is great! especially when you cook it with some vegetable and egg. I like it very much, though it's more expensive than the other noodles\"*\n",
    "\n",
    "\n",
    "* *\"Quite tasteless and they make you order so many. I am stuck with 12 bags of this tasteless stuff. I am not ordering large amounts of anything from Amazon again. So often I don't like it and I am stuck with so much on hand.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict(reviews, w2v, gbm):\n",
    "    \n",
    "    words = tokenize(reviews[\"Text\"].ascharacter())\n",
    "    reviews_vec = w2v.transform(words, aggregate_method=\"AVERAGE\")\n",
    "    \n",
    "    summary_words = tokenize(reviews[\"Summary\"].ascharacter())\n",
    "    summary_vec = w2v.transform(summary_words, aggregate_method=\"AVERAGE\")\n",
    "    \n",
    "    model_data = reviews.cbind(reviews_vec).cbind(summary_vec)\n",
    "    print(gbm.predict(model_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "good_review = h2o.H2OFrame([[\"B000EQT574\", \"AISQLBDGS2KXR\", 1, 1, 1263340800, \n",
    "                             \"Delicious\",\n",
    "                             \"These chips are delicious. Salty sweet with a hint of spice. I have no idea how Tamari is supposed to taste, but these chips are awesome. I just finished an entire bag in one day!\"]])\n",
    "\n",
    "good_review.col_names = [\"ProductId\",\"UserId\",\"HelpfulnessNumerator\",\"HelpfulnessDenominator\",\"Time\",\"Summary\",\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bad_review = h2o.H2OFrame([[\"B003BJZMSM\", \"A2JBZHQVQF7MV0\", 1, 2, 1274832000, \n",
    "                            \"Pretty tasteless\",\n",
    "                            \"Quite tasteless and they make you order so many. I am stuck with 12 bags of this tasteless stuff. I am not ordering large amounts of anything from Amazon again. So often I don't like it and I am stuck with so much on hand.\"]])\n",
    "\n",
    "bad_review.col_names = [\"ProductId\",\"UserId\",\"HelpfulnessNumerator\",\"HelpfulnessDenominator\",\"Time\",\"Summary\",\"Text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Predict!\n",
    "print(\"Good Review: \")\n",
    "print(predict(good_review, w2v_model, gbm_embeddings))\n",
    "\n",
    "print(\"Bad Review: \")\n",
    "print(predict(bad_review, w2v_model, gbm_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "h2o.cluster().shutdown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}